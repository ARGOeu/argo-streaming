[HDFS]
# hdfs namenode host
hdfs_host: hdfs_test_host
# hdfs namenode port 
hdfs_port: hdfs_test_port
# hdfs user 
hdfs_user: hdfs_test_user
# hdfs rollback days:
rollback_days: 3
# hdfs path for metric data
hdfs_metric: hdfs://{{hdfs_host}}:{{hdfs_port}}/user/{{hdfs_user}}/argo/tenants/{{tenant}}/mdata
# hdfs path for sync data
hdfs_sync: hdfs://{{hdfs_host}}:{{hdfs_port}}/user/{{hdfs_user}}/argo/tenants/{{tenant}}/sync

[LOGS]
# log handlers to support 
log_modes: console,syslog,file
# global log level
log_level: info
# specific level for syslog handler
syslog_level: critical
# specific level for file handler
file_level: warning
# specific level for console handler
console_level: info
# socket for syslog handler 
syslog_socket: /dev/log
# path for file handler
file_path:

[FLINK]
# path for flink executable
path: flink_path
# url for flink job manager 
job_manager:

[JOB-NAMESPACE]
# Template to check if a metric job with similar name already runs
ingest-metric-namespace: Ingesting data from {{ams_endpoint}}:{{ams_port}}/v1/projects/{{project}}/subscriptions/{{ams_sub}}
# Template to check if a sync job with similar name already runs
ingest-sync-namespace: Ingesting sync data from {{ams_endpoint}}:{{ams_port}}/v1/projects/{{project}}/subscriptions/{{ams_sub}}

[CLASSES]
# Specify class to run during job submit 
ams-ingest-metric: test_class
ams-ingest-sync: test_class
batch-ar: test_class
batch-status: test_class

[JARS]
# Specify jar to run during job submit 
ams-ingest-metric: test.jar
ams-ingest-sync: test.jar
batch-ar: test.jar
batch-status: test.jar

[AMS]
# AMS service port 
ams_port: test_port
# Ams service endpoint
ams_endpoint: test_endpoint

# Tenant General Configuration
[TENANTS:TENANTA]
# Map tenant to AMS project
ams_project:test_project
# Tenant's AMS token
ams_token:test_token

# report names per tenant
[TENANTS:TENANTA:REPORTS]
# report UUID
report_name : report_uuid

# tenant specific mongo configuration
[TENANTS:TENANTA:MONGO]
# mongo host
mongo_host: mongo_test_host
# mongo port
mongo_port: mongo_test_port
# mongo uri for batch ar
mongo_uri: mongodb://{{mongo_host}}:{{mongo_port}}/argo_TENANTA

# Tenant-job specific configuration
[TENANTS:TENANTA:ingest-metric]
# AMS subscription for ingesting data
ams_sub: job_name
# Interval between each ingestion request
ams_interval: 300
# Max number of messages to ingest each time
ams_batch: 100
# Path to save flink checkpoint
checkpoint_path:test_path
# Interval between flink checkpoints
checkpoint_interval: 30000
[TENANTS:TENANTA:ingest-sync]
ams_sub: job_name
ams_interval: 3000
ams_batch: 100

