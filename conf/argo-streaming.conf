[HDFS]
namenode=hdfs://localhost:8020
user= foo
rollback_days= 3
path_metric= hdfs://{{namenode}}/user/{{hdfs_user}}/argo/tenants/{{tenant}}/mdata
path_sync= hdfs://{{namenode}}/user/{{hdfs_user}}/argo/tenants/{{tenant}}/sync
writer_bin= /home/root/hdfs

[STREAMING]
kafka_servers=localhost:9092

[API]
endpoint=https://api_host
access_token=token01
tenants=TENANT_A,TENANT_B
TENANT_A_key=key1
TENANT_B_key=key2

[MONGO]
endpoint=mongodb://localhost:21017

[AMS]
endpoint: test_endpoint:8080
access_token: foo_token
# Ams proxy
proxy:test_proxy
# Verify ssl
verify: true

[FLINK]

path= /path/to/flink
job_manager= http://localhost:8081

[JOB-NAMESPACE]
ingest-metric-namespace= Ingesting  metric data from {{ams_endpoint}}:{{ams_port}}/v1/projects/{{project}}/subscriptions/{{ams_sub}}
ingest-sync-namespace= Ingesting sync data from {{ams_endpoint}}:{{ams_port}}/v1/projects/{{project}}/subscriptions/{{ams_sub}}
stream-status-namespace= Streaming status using data from {{ams_endpoint}}:{{ams_port}}/v1/projects/{{project}}/subscriptions/[{{ams_sub_metric}},{{ams_sub_sync}}]

[CLASSES]
ams-ingest-metric= argo.streaming.AmsIngestMetric
ams-ingest-sync= argo.streaming.AmsIngestSync
batch-ar= argo.batch.ArgoArBatch
batch-status= argo.batch.ArgoStatusBatch
stream-status= argo.streaming.AmsStreamStatus

[JARS]
ams-ingest-metric= /path/to/ams-ingest-metric-close.jar
ams-ingest-sync= /path/to/ams-ingest-sync-0.1.jar
batch-ar= /path/to/ArgoArBatch-1.0.jar
batch-status= /path/to/ArgoStatusBatch-1.0.jar
stream-status= /path/to/streaming-status-multi2.jar


[TENANTS:TENANT_A]
ams_project= TENANT_A
ams_token= key_1
mongo_uri= {{mongo_uri}}/argo_{{tenant}}
mongo_method: insert
reports= report1,report2
report_report1= uuid1
report_report2= uuid2

[TENANTS:TENANT_A:ingest-metric]
ams_sub= ingest_metrict
ams_interval= 300
ams_batch= 100
checkpoint_path= hdfs://localhost:8020/user/foo/check
checkpoint_interval= 30000

[TENANTS:TENANT_A:ingest-sync]
ams_sub= ingest_sync
ams_interval= 300
ams_batch= 100
checkpoint_path= hdfs://localhost:8020/user/foo/checkt
checkpoint_interval= 30000

[TENANTS:TENANT_A:stream-status]
ams_batch= 100
ams_interval= 100
ams_sub_metric= status_metric
ams_sub_sync= status_sync
kafka_servers= localhost:9092
kafka_topic= topic.tenant_a
flink_parallelism= 1
outputs= kafka

[TENANTS:TENANT_B]
ams_project= TENANT_B
ams_token= key_1
mongo_uri= {{mongo_uri}}/argo_{{tenant}}
mongo_method: insert
reports= report1,report2
report_report1= uuid1
report_report2= uuid2

[TENANTS:TENANT_B:ingest-metric]
ams_sub= ingest_metrict
ams_interval= 300
ams_batch= 100
checkpoint_path= hdfs://localhost:8020/user/foo/check
checkpoint_interval= 30000

[TENANTS:TENANT_B:ingest-sync]
ams_sub= ingest_sync
ams_interval= 300
ams_batch= 100
checkpoint_path= hdfs://localhost:8020/user/foo/checkt
checkpoint_interval= 30000

[TENANTS:TENANT_B:stream-status]
ams_batch= 100
ams_interval= 100
ams_sub_metric= status_metric
ams_sub_sync= status_sync
kafka_servers= localhost:9092
kafka_topic= topic.tenant_a
flink_parallelism= 1
outputs= kafka
